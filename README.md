# **YouTube Video Q&A with RAG**  

ğŸš€ **A Retrieval-Augmented Generation (RAG) system that lets you ask questions about any YouTube video and get accurate, context-aware answers.**  

---

## **ğŸ“Œ Features**  

âœ… **Transcript Extraction** â€“ Automatically fetches YouTube video captions.  
âœ… **Smart Chunking** â€“ Splits long transcripts into meaningful segments.  
âœ… **Semantic Search** â€“ Uses **HuggingFace embeddings** + **FAISS vector DB** for fast retrieval.  
âœ… **AI-Powered Answers** â€“ Generates responses using **Cohereâ€™s LLM** (or local models like Mistral).  
âœ… **Interactive Chat UI** â€“ Built with **Streamlit** for a seamless user experience.  
âœ… **Persistent Storage** â€“ Saves processed videos locally for faster reloads.  

---

## **âš™ï¸ Tech Stack**  

| Component | Technology |  
|-----------|------------|  
| **Backend** | FastAPI, LangChain |  
| **Vector DB** | FAISS (Facebook AI Similarity Search) |  
| **Embeddings** | HuggingFace `all-MiniLM-L6-v2` |  
| **LLM** | Cohere `command` (or Ollama for local models) |  
| **Frontend** | Streamlit |  
| **Transcript Fetching** | `youtube-transcript-api` |  

---

## **ğŸš€ Quick Start**  

### **1. Clone the Repository**  
```bash
git clone https://github.com/your-username/youtube-rag.git
cd youtube-rag
```

### **2. Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **3. Set Up API Keys**  
Create a `.env` file:  
```env
COHERE_API_KEY="your_cohere_key"  # Optional (if using Cohere)
HUGGINGFACEHUB_API_TOKEN="your_hf_token"  # Optional (if using HF models)
```

### **4. Run the Backend (FastAPI)**  
```bash
uvicorn backend.main:app --reload
```

### **5. Run the Frontend (Streamlit)**  
```bash
streamlit run frontend/app.py
```
ğŸ“Œ Open `http://localhost:8501` in your browser.  

---

## **ğŸ› ï¸ How It Works**  

1. **User Input** â†’ Enter a YouTube video ID (e.g., `dQw4w9WgXcQ`).  
2. **Transcript Processing** â†’ Fetches captions, splits into chunks, and stores embeddings in FAISS.  
3. **Question Handling** â†’ Searches for relevant chunks and generates an answer using an LLM.  
4. **Response** â†’ Displays a natural-language answer with source context.  

---

## **ğŸ” Example Queries**  

â“ *"What is the main topic of this video?"*  
â“ *"Explain the key points about [topic]."*  
â“ *"Does this video mention [specific detail]?"*  

---

## **ğŸ“‚ Project Structure**  

```plaintext
youtube-rag/  
â”œâ”€â”€ backend/  
â”‚   â”œâ”€â”€ main.py           # FastAPI server  
â”‚   â”œâ”€â”€ rag_processor.py  # Core RAG logic  
â”‚   â””â”€â”€ requirements.txt  
â”œâ”€â”€ frontend/  
â”‚   â”œâ”€â”€ app.py            # Streamlit UI  
â”‚   â””â”€â”€ requirements.txt  
â”œâ”€â”€ .env                  # API keys  
â””â”€â”€ README.md  
```

---

## **ğŸ“Œ Future Improvements**  

ğŸ”¹ **Add Timestamp References** â€“ Link answers to exact video timestamps.  
ğŸ”¹ **Support Local LLMs** â€“ Integrate Ollama for offline usage.  
ğŸ”¹ **Multilingual Support** â€“ Expand beyond English transcripts.  
ğŸ”¹ **Deploy to Cloud** â€“ Host on **Hugging Face Spaces** or **Streamlit Cloud**.  

---

## **ğŸ“œ License**  
MIT License - Free for personal and academic use.  

---

## **ğŸ’¡ Contribute**  
Found a bug? Want to improve something? Open an **issue** or submit a **PR**!  

ğŸ“§ **Contact**: [gautam2002gkp@gmail.com]  

--- 
